{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9U4uFy843eFM"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
        "\n",
        "import numpy as np\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "-5XJy6FK7OTc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = '/content/drive/MyDrive/Colab Notebooks/data/animal'\n",
        "width = height = 224\n",
        "\n",
        "idg = ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "\n",
        "    # Augmentation\n",
        "    horizontal_flip = True,\n",
        "    zoom_range = 0.1,\n",
        "    rotation_range = 15,\n",
        "    brightness_range = (0.9, 1.1),\n",
        "    #preprocessing_function = اسم تایعی که میخوایم تغیییرات دلخواه به دیتاها بدهیم قبلش باید تابع تعریف کنیم\n",
        "    validation_split = 0.2\n",
        ")\n",
        "\n",
        "train_data = idg.flow_from_directory(\n",
        "    dataset_path,\n",
        "    target_size = (width, height),\n",
        "    # save_to_dir = '/content/drive/MyDrive/Colab Notebooks/data/augmented_data',\n",
        "    class_mode= 'categorical',\n",
        "    subset = 'training'\n",
        ")\n",
        "\n",
        "val_data = idg.flow_from_directory(\n",
        "    dataset_path,\n",
        "    target_size = (width, height),\n",
        "    class_mode= 'categorical',\n",
        "    subset = 'validation'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXH7WU377Q7n",
        "outputId": "a24f3e29-ea14-450a-be99-0ee19a60836e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1061 images belonging to 5 classes.\n",
            "Found 263 images belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "_oG4K0yzFO-X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    Conv2D(16, (3,3), activation='relu', input_shape=(width, height, 3)),\n",
        "    Conv2D(16, (3,3), activation='relu'),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(32, (3,3), activation='relu'),\n",
        "    Conv2D(32, (3,3), activation='relu'),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(32, (3,3), activation='relu'),\n",
        "    Conv2D(32, (3,3), activation='relu'),\n",
        "    MaxPool2D(),\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    MaxPool2D(),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(256, activation = 'relu'),\n",
        "    Dense(125, activation = 'relu'),\n",
        "    Dense(5, activation='softmax'),\n",
        "])"
      ],
      "metadata": {
        "id": "enVm1UnJFMzy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss = tf.keras.losses.categorical_crossentropy,\n",
        "              metrics= ['accuracy']\n",
        "              )"
      ],
      "metadata": {
        "id": "BISYqde-H31W"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train\n",
        "model.fit(train_data, validation_data = val_data, epochs=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymvMlVMcKpG2",
        "outputId": "d0340aef-7509-494f-da2f-e7438d80030c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "34/34 [==============================] - 427s 12s/step - loss: 1.6043 - accuracy: 0.2281 - val_loss: 1.5844 - val_accuracy: 0.2395\n",
            "Epoch 2/20\n",
            "34/34 [==============================] - 42s 1s/step - loss: 1.5225 - accuracy: 0.3129 - val_loss: 1.5378 - val_accuracy: 0.2662\n",
            "Epoch 3/20\n",
            "34/34 [==============================] - 41s 1s/step - loss: 1.4545 - accuracy: 0.3374 - val_loss: 1.3757 - val_accuracy: 0.3422\n",
            "Epoch 4/20\n",
            "34/34 [==============================] - 38s 1s/step - loss: 1.3635 - accuracy: 0.3940 - val_loss: 1.3270 - val_accuracy: 0.3726\n",
            "Epoch 5/20\n",
            "34/34 [==============================] - 38s 1s/step - loss: 1.3082 - accuracy: 0.4090 - val_loss: 1.3358 - val_accuracy: 0.3840\n",
            "Epoch 6/20\n",
            "34/34 [==============================] - 39s 1s/step - loss: 1.2692 - accuracy: 0.4515 - val_loss: 1.3703 - val_accuracy: 0.3954\n",
            "Epoch 7/20\n",
            "34/34 [==============================] - 39s 1s/step - loss: 1.2361 - accuracy: 0.4675 - val_loss: 1.2662 - val_accuracy: 0.4144\n",
            "Epoch 8/20\n",
            "34/34 [==============================] - 42s 1s/step - loss: 1.1715 - accuracy: 0.4910 - val_loss: 1.1640 - val_accuracy: 0.4943\n",
            "Epoch 9/20\n",
            "34/34 [==============================] - 42s 1s/step - loss: 1.1104 - accuracy: 0.5306 - val_loss: 1.1583 - val_accuracy: 0.4943\n",
            "Epoch 10/20\n",
            "34/34 [==============================] - 38s 1s/step - loss: 1.0602 - accuracy: 0.5551 - val_loss: 1.1364 - val_accuracy: 0.5057\n",
            "Epoch 11/20\n",
            "34/34 [==============================] - 38s 1s/step - loss: 0.9700 - accuracy: 0.5938 - val_loss: 1.1288 - val_accuracy: 0.4943\n",
            "Epoch 12/20\n",
            "34/34 [==============================] - 39s 1s/step - loss: 0.9696 - accuracy: 0.5872 - val_loss: 1.2217 - val_accuracy: 0.4373\n",
            "Epoch 13/20\n",
            "34/34 [==============================] - 39s 1s/step - loss: 0.9412 - accuracy: 0.6023 - val_loss: 1.1918 - val_accuracy: 0.4905\n",
            "Epoch 14/20\n",
            "34/34 [==============================] - 38s 1s/step - loss: 0.8816 - accuracy: 0.6475 - val_loss: 1.1045 - val_accuracy: 0.5741\n",
            "Epoch 15/20\n",
            "34/34 [==============================] - 39s 1s/step - loss: 0.8542 - accuracy: 0.6400 - val_loss: 1.1151 - val_accuracy: 0.5475\n",
            "Epoch 16/20\n",
            "34/34 [==============================] - 39s 1s/step - loss: 0.7680 - accuracy: 0.6880 - val_loss: 1.1503 - val_accuracy: 0.5437\n",
            "Epoch 17/20\n",
            "34/34 [==============================] - 39s 1s/step - loss: 0.7527 - accuracy: 0.7078 - val_loss: 1.0731 - val_accuracy: 0.5171\n",
            "Epoch 18/20\n",
            "34/34 [==============================] - 39s 1s/step - loss: 0.6723 - accuracy: 0.7314 - val_loss: 1.2569 - val_accuracy: 0.4943\n",
            "Epoch 19/20\n",
            "34/34 [==============================] - 38s 1s/step - loss: 0.6335 - accuracy: 0.7436 - val_loss: 1.0527 - val_accuracy: 0.5779\n",
            "Epoch 20/20\n",
            "34/34 [==============================] - 42s 1s/step - loss: 0.6414 - accuracy: 0.7625 - val_loss: 1.2106 - val_accuracy: 0.5475\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7cf95299b9d0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test"
      ],
      "metadata": {
        "id": "XOEN5-euNUfj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = '/content/drive/MyDrive/Colab Notebooks/data/animal/test'\n",
        "width = height = 224\n",
        "\n",
        "idg = ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "\n",
        ")\n",
        "\n",
        "test_data = idg.flow_from_directory(\n",
        "    dataset_path,\n",
        "    target_size = (width, height),\n",
        "    class_mode= 'categorical',\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "YLspfooYN6vi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_data)"
      ],
      "metadata": {
        "id": "u_6TcN78NbAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference"
      ],
      "metadata": {
        "id": "e8Xd39qqOdoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.imread('/content/4.jpg')\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "image = cv2.resize(image, (width, height))\n",
        "image = image / 255\n",
        "image = image.reshape(1, width, height, 3)  #3d, 4d\n",
        "\n",
        "result = model.predict(image)\n",
        "pred = np.argmax(result)\n",
        "\n",
        "if pred == 2:\n",
        "  print('🐘')\n",
        "elif pred == 3:\n",
        "  print('🦒')\n",
        "elif pred == 4:\n",
        "  print('🐼')\n",
        "elif pred == 0:\n",
        "  print('😺')\n",
        "elif pred == 1:\n",
        "  print('🐶')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORD7nQevOhk0",
        "outputId": "72a0e61b-3643-4ce7-eeab-dfe67ae1441c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 24ms/step\n",
            "🐼\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9qRWEl2vOWRc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}